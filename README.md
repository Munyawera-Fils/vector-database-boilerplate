# Vector Database Course
Welcome to the Vector Database Course! In this course, you'll learn how to create, integrate, and query vector databases. We will create a simple application that will have a that is connected to OpenAI's GPT but augement it's knowledge with your own data via a vector database.

<!-- TODO: Add usecases -->

# Usecases

1. **Natural Language Understanding (NLU):** Embeddings can be used to convert text into numerical representations that capture the meaning and context of the text. These embeddings can be used in NLU tasks, such as sentiment analysis, named entity recognition, and text classification.

2. **Search Engines:** Embeddings can be employed to enhance the performance of search engines. By converting user queries and indexed documents into embeddings, search engines can deliver more accurate and relevant search results.

> In this vector boilplate  we will use the vector database to extend the knowledge of openAI models which by now they only internet information up to 2020.

### What You Will Learn:
Throughout this course, you will acquire the following essential skills:

1. **Vector Database Creation and Utilization**: You will learn to create and set up a vector database and use it to store and retrieve vectors.
2. **Embedding Generation and Integration**: Learn how to generate embeddings to transform text input into vectors and integrate them into your vector database.
3. **Vector Database Querying**: You will learn how to query your vector database to retrieve vectors and implement them into chatresponses with OpenAI's GPT-3.

### What are Vectors and Embeddings?
Embeddings are a form of feature engineering used predominantly in machine learning to convert text or other data into numerical vectors. These vectors capture semantic meaning and contextual relationships among words or items, making it easier for machine learning algorithms to understand text. Various algorithms like Word2Vec, GloVe, and BERT offer different methods for generating embeddings.

For instance, in the case of the word 'happy', it gets converted into a numerical array, say `[0.12, 0.25, -0.47, ...]`, in a 300-dimensional space. This high-dimensionality allows the model to understand nuanced relationships, like how 'happy' is closer in meaning to 'joyful' than to 'sad'.

Embeddings are not just for word representation; they are pivotal in various NLP tasks such as sentiment analysis, text classification, and even machine translation.

### What is a Vector Database?
A vector database is a specialized data storage and retrieval system designed to manage high-dimensional vectors like the ones generated by embeddings. Unlike traditional databases that are optimized for text or numerical data, vector databases are engineered to perform fast similarity searches within the high-dimensional space where these vectors reside.

To draw a parallel, if embeddings are the language that machine learning algorithms use to understand text, then a vector database is like a highly efficient library for this language. This 'library' can quickly identify which 'words' (vectors) are similar to a given 'word' (query vector), making it incredibly useful for tasks such as recommendation systems, similarity searches, and even enhancing chatbot intelligence.

For instance, after converting a text query into its corresponding vector using embeddings, you could search a vector database for the most similar vectors. These could then be used to generate chatbot responses, recommend products, or classify the text.

### Prerequisites
In order to follow along with this course, you will need to have the following:

- **Node.js (Version 12 or higher)**: You should have Node.js installed on your machine. If you do not, you can download it [here](https://nodejs.org/en/download/).
- **Basic React Knowledge**: You should be familiar with React and Next.js. If you are not, you can check out the [React documentation](https://reactjs.org/docs/getting-started.html) and the [Next.js documentation](https://nextjs.org/docs/getting-started).
- **Basic Node.js Knowledge**: You should be familiar with Node.js. If you are not, you can check out the [Node.js documentation](https://nodejs.org/en/docs/).

### Tech Stack
Here are the technologies we will be using in this tutorial:

- [Supabase](https://supabase.io/) - Supabase is an open-source Firebase alternative. It allows you to create vector databases and store and retrieve vectors.
- [Langchain](https://js.langchain.com/) - Langchain an open-source framework for developing applications powered by large language models (LLMs). 
- [OpenAI API](https://openai.com/) - The OpenAI API gives you access to powerful AI models, such as the GPT-3 model, which we will be using in this tutorial.
- [Next.js](https://nextjs.org/) - Next.js is a React framework for building server-side rendered and statically generated applications.
- [Codespaces](https://github.com/codespaces) - Codespaces is a cloud-based development environment that allows you to develop entirely in the cloud.

### Overview

1. Set Up Your Supabase Project
2. Set Up the Next.js Boilerplate
3. Create 


## 1. Set Up Your Supabase Project

1. Create an account on [supabase.com](https://supabase.com/dashboard/sign-in?) if you don't have one.

2. Create a new project on Supabase.

   - Creating a New Project

   ![Imgur](https://i.imgur.com/oSUNLCV.png)

   - Click on the button to create a new project.

   ![Imgur](https://i.imgur.com/12pOep0.png)

   ![Imgur](https://i.imgur.com/zaRDMnH.png)

   - Click on the "Create New Project" Button.

   ![Imgur](https://i.imgur.com/cjQcuc4.png)

3. Enable Supabase to Store Vector Datatypes

   Initially, when you create a PostgreSQL database, you are not able to implicitly insert or deal with vector datatypes. To enable PostgreSQL to handle vector datatypes, follow these steps:

   - Click the SQL editor button.

   ![Imgur](https://i.imgur.com/RBdDx0Y.png)

   - Click on Quickstarts.

   ![Imgur](https://i.imgur.com/1olGXAC.png)

   - We will use langchain, It's recommended that we select quickstart from langchain.

   ![Imgur](https://i.imgur.com/u4MSw0l.png)

   - Click on run.

   ![Imgur](https://i.imgur.com/PDJ0sdC.png)
 

   ![Imgur](https://i.imgur.com/Ul2d7jP.png)

   After running the query, no rows will be returned, and you will receive a success message.

Now that you have created your own project and vector database, we can proceed to integrate it, create embeddings, upload them, and query the vector database.

## 2. Set Up the Next.js Boilerplate
You can either use Codespaces or your local machine to set up the boilerplate. If you are using Codespaces, skip to the next section. Otherwise, follow the steps below.

### 2.1.1 Option 1: Codespaces Boilerplate Setup
GitHub Codespaces provides a complete, ready-to-use  cloud-based dev environment in your browser. It saves you from the need for local setup, allowing you to concentrate on learning and building.

1. Create a GitHub account if you don't have one.

2. To create a new Codespace with the boilerplate, go to the 
[Vectordatabase-boilerplate repository](](https://github.com/dacadeorg/vector-database-boilerplate)).
3. Click on the "Use this template" button and then, click on "Open with Codespaces." 
   
When opening the Codespace, it will automatically install the dependencies.

### 2.1.2 Option 2: Local Machine Boilerplate Setup

1. Clone this repository:
  ```
  git clone https://github.com/dacadeorg/vector-database-boilerplate.git
  ```
2. Move to the project directory:
  ```
  cd vector-database-boilerplate
  ```
3. Install dependencies:

  ```
  npm install
  ```

### 2.2 Set Up Environment Variables
Open the `.env.example` file and add your OpenAI API key, Supabase project API key, and Supabase reference ID. 

**1. OpenAI API Key**

Your `OPENAI_API_KEY` key can be located in your [OpenAI Dashboard](https://platform.openai.com/account/api-keys).

**2. Supabase Reference ID**

To get your `SUPABASE_REFERENCE_ID`, click on the settings icon on the sidebar menu of your Supabase project, copy the Reference ID, and assign it to `SUPABASE_REFERENCE_ID`. 

![Imgur](https://i.imgur.com/oSUNLCV.png)
`SUPABASE_REFERENCE_ID=` - 

**3. Supabase Project API Key**

To get `SUPABASE_PROJECT_API_KEY`, click on [API](https://supabase.com/dashboard/project/ktrkrjsmtaomgqtvyppm/settings/api), click copy, and assign it to your `SUPABASE_PROJECT_API_KEY` in your `.env.example` file. Copy only the key with `anon` and `public` labels.

![Imgur](https://i.imgur.com/A5kifxw.png)

**4. Rename .env.example to .env**

Rename .env.example to .env.

### 2.3 Run the Boilerplate
```bash
npm run dev
```
Access the application by navigating to [http://localhost:3000](http://localhost:3000/). The boilerplate application should now be live.

## 3. Test the Boilerplate
The boilerplate application is a simple chatbot that uses OpenAI's GPT-3 model to generate responses. It is not connected to the vector database yet. To test it, type a message in the input field and press enter. The chatbot will respond with a message generated by the GPT-3 model.

### 3.1 Test the Boilerplate in the Browser
  ![Imgur](https://i.imgur.com/UfspVk7.png)

### 3.2 Test the Boilerplate in the Terminal
  ![Imgur](https://i.imgur.com/Kkfirgn.png)

## 4. Exploring the Boilerplate Code
<!-- TODO Explain very high-level the general structure of the code without going into too much detail. Then Explain the most important files in more detail. I provided some example but maybe other files are more relevant. -->

### 4.1 `pages/api/openai.js`

`pages/api/openai.js `: With the help of langchain this endpoint enables us to make similaty search to get meaningful context out of our vector store.

`new OpenAIEmbeddings({ openAIApiKey: process.env.OPENAI_API_KEY })`: this portion of code will initialize openai with `text-embedding-ada-002`.

This is how `text-embedding-ada-002` is working.
![Imgur](https://i.imgur.com/TADgWR5.png)


```javascript
  const vectorStore = await SupabaseVectorStore.fromExistingIndex(
    new OpenAIEmbeddings({ openAIApiKey: process.env.OPENAI_API_KEY }),
    {
      client: supabase,
      tableName: "documents",
      queryName: "match_documents",
    }
  );
```

`vectorStore.asRetriever()`: Here we are using asRetriever for to load our vector store.

```javascript
 // Here langchain will use `text-davinci-003` by default.
 const chain = ConversationalRetrievalQAChain.fromLLM(
    model,
    vectorStore.asRetriever()
  );

  /**
   * 
   *  Now that we have our vector store loaded with `text-davinci-003` model. We can now query it
   *  with chain.call() which receives an object with question and chat_history.
   *  chat_history helps the model to be aware of the chat history, [ { role: "assistant", content: "" }, { role: "user", content: "" }]
   * 
   * */
  const answer = await chain.call({ question: question, chat_history: [] });
```

### 4.2 `pages/api/embed.js`

`RecursiveCharacterTextSplitter()`: will help you split the content into chunks, and that content will be transformed into vectors.

`SupabaseVectorStore`: This is an instance that merges your Supabase client with the logic of Langchain and the OpenAI model that converts documents into vectors. Langchain uploads them to Supabase.

```javascript
await SupabaseVectorStore.fromDocuments(
    splittedDocs,
    new OpenAIEmbeddings({
        openAIApiKey: process.env.OPENAI_API_KEY,
    }),
    {
        client: supabase,
        tableName: "documents",
    }
);
```

## Generate Vectors from a Text File

```bash
node ./scripts/uploadEmbedding.js
```

Don't worry about this warning: "No storage option exists to persist the session, which may result in unexpected behavior when using auth. If you want to set `persistSession` to true, please provide a storage option, or you may set `persistSession` to false to disable this warning." Just wait until you see "Uploaded" logged in the terminal.

## Query Our Vector Database

Head over to where our app is running [http://localhost:3000](http://localhost:3000/), and ask any query related to bun, or if you changed the content inside the [document.txt](./scripts/content/document.txt), try to query anything about them.

#### Background Process

```js
/*

This line creates an instance of the SupabaseVectorStore class by calling the fromExistingIndex method. It takes two arguments:
The first argument is an instance of the OpenAIEmbeddings class, which is initialized with an object containing the OpenAI API key.

The second argument is an object with properties client, tableName, and queryName. These properties specify the Supabase client, the name of the table, and the name of the query to be used for retrieving vectors from the Supabase database.

*/

const vectorStore = await SupabaseVectorStore.fromExistingIndex(
    new OpenAIEmbeddings({ openAIApiKey: process.env.OPENAI_API_KEY }),
    { client: supabase, tableName: "chunks", queryName: "match_chunks" }
);

/*

This line creates an instance of the ConversationalRetrievalQAChain class by calling the fromLLM method. It takes two arguments:
The first argument is the model object, which represents the language model to be used for conversational retrieval.
The second argument is the result of calling the asRetriever method on the vectorStore object. This method returns a retriever object that can be used for retrieving vectors from the Supabase database.

*/

const chain = ConversationalRetrievalQAChain.fromLLM(
    model,
    vectorStore.asRetriever()
);

/*

This line calls the call method on the chain object to perform a conversational retrieval. It takes an object as an argument with properties question and chat_history. The question property contains the question to be asked. 
The chat_history property is an array that can be used to provide previous conversation history if needed.

*/
const answer = await chain.call({ question: question, chat_history: [] });

/*
Finally, we deliver the response to the client.
*/

return res.status(200).json({ data: answer });
```

## 5. Conclusion

In summary, this course has equipped you with the essential skills to work with vector databases. You've learned how to create, integrate, and query these databases, which will help you manage data more efficiently. With these practical skills, you're ready to utilize vector databases for various applications.